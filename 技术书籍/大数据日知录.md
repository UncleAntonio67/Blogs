作者： 张俊林                        
阅读日期：20250904——20250930
学习方式：书本阅读

# 前言

本书专注于与大数据处理有关的架构与算法。

# 目录

第0章——当谈论大数据时我们在谈什么
第1章——数据分片与路由
第2章——数据复制与一致性
第3章——大数据常用的算法与数据结构
第4章——集群资源管理与调度
第5章——分布式协调系统
第6章——分布式通信
第7章——数据通道
第8章——分布式文件系统
第9章——内存KV数据库
第10章——列式数据库
第11章——大规模批处理系统
第12章——流式计算
第13章——交互式数据分析
第14章——图数据库：架构与算法
第15章——机器学习：范型与架构
第16章——机器学习：分布式算法
第17章——增量计算

# 第0章——当谈论大数据时我们在谈什么

## 大数据是什么

多大才算大：数据量的衡量单位，从小到大依次为KB、MB、GB、TB、PB、EP和ZB

电子数据正在暴涨：2010年全世界信息总量是1ZB，最近3年人类产生的信息量已经超过了之前历史上人类产生的所有信息之和。

大数据的定义：
- 维基百科：数据量太大，手头的工具已经不便于管理
- IBM：3V（Volume、Velocity、Variety）+1V（Value）
- IDC：代表新一代的技术脚骨，能够高速获取数据进行分析挖掘，抽取价值信息
- Google：海量数据可广泛获得，所稀缺的是如何从中挖掘出智慧和观点。

## 大数据之翼：技术范型转换

关系型数据库——>并行数据库——>NoSql数据库

整体架构：
——>数据源
来源各异，形式不规整
——>数据管理
NoSQL不追求应用场景的统一，而且不同类型不同NoSQL库存储管理
——>数据分析
挖掘分析，利用数据挖掘、机器学习、时序分析
——>数据获取
数据可视化展现

大数据技术处理架构图
![[Pasted image 20250904182932.jpg]]

## 大数据商业炼金术

互联网、传统IT、金融、零售行业都在利于大数据提升企业收益

## 大数据在路上

概念最早由麦肯锡提出，巨型公司提供基础架构平台，中小型创业公司完善分布式计算生态系统，或者提供大数据服务等。

# 第1章——数据分片与路由

数据规模越来越大：
- 并行数据库通过纵向扩展解决问题（Scale Up），扩展机器
- 大数据系统通过横向扩展解决问题（Scale Out），增加机器

增加机器就带来了**数据分片**，分片后就必须找到数据，即**数据路由**。

- 数据分片：实现水平扩展
- 数据复制：保证数据高可用，因为服务器经常存在故障，所以需要存储多份副本

数据复制面临的问题：并发对数据更新时，如何保证数据的一致性。

常见的数据分片方法包括哈希分片与范围分片，先讲通用模型再将具体实现。

## 抽象模型

二级映射：第一级：key-partition，一个分片包含多个数据记录；第二级：partition-machine，一个物理机器容纳多个数据分片。

![[Pasted image 20250904184458.jpg]]

在做数据分片时，根据key-partition映射关系将大数据水平切割成众多数据分片，然后再按照partition-machine映射关系将数据分片放置到对应的物理机器上。

- 哈希分片：主要通过哈希函数来建立key-partition映射关系，**点查询**，不支持范围查询。Dynamo、Cassandra、Riak、Voldmort、Membase等都支持
- 范围分片：**支持点查询也可以支持范围查询**，包括Google的BigTable和微软的Azure等系统

## 哈希分片

通过哈希函数分片，有三种哈希分片方式：Round Robin、虚拟桶及一致性哈希方法
### **Round Robin**
就是哈希取模法，哈希函数：H(key) = hash(key) mod K。机器编号0-K-1，全部数据分配到K台物理机。

- 优点：非常简单
- 缺点：灵活性差，增加一个节点，就需要重分布

它是物理机和数据分片的二合一，机器和映射函数紧耦合，这是缺乏扩展灵活性的根本原因。

### 虚拟桶

MemBase对于数据分片管理提出了虚拟桶的实现方式：
记录和物理机引入虚拟桶，数据线到桶，再到物理机，都是多对一的映射。

虚拟桶层就是数据分片层，key-partition映射采用哈希函数，而partition-machine映射采用表格管理实现。
![[Pasted image 20250905104631.jpg]]
系统灵活性、扩展性更强

### 一致性哈希

分布式哈希表：哈希表的分布式扩展。
一致性哈希就是分布式哈希的一种实现方式。

“一致性哈希”算法将哈希数值空间按照大小组成一个首尾相接的环状序列。对于每台机器，可以根据其IP和端口号经过哈希函数映射到哈希数值空间内，这样不同的机器就成了环状序列中的不同节点。
![[Pasted image 20250908145043.jpg]]
**路由方面**：可以在每个机器节点配置路由表，路由表存储m 条路由信息，其中第i 项（0≤i ≤m −1）路由信息代表距离当前节点为2 i 的哈希空间数值所在的机器节点编号。
通常情况下，路由算法发送的消息不会多于m 条，因为这个过程类似于在0～(2 m −1)数值空间上的二分查找法。

**扩展方面**：首先增加节点对应的前驱和后继节点关系，然后还需要进行数据重分布。并发情况下需要进行稳定性检测。

**离开方面**：正常离开进行通知准备，进行数据重分布，异常离开通过数据多副本保障。

**虚拟节点**：两个问题，节点到环状结构的位置随机，容易存在负载不均衡的问题，另外不同机器间的性能也不同。所以引入虚拟节点，即将一个物理节点虚拟成若干虚拟节点，分别映射到一致性哈希的环状结构不同位置。这样一方面可以导致更佳的负载均衡，也可以兼顾到机器异质性问题。

**一致性哈希**：将集群机器数目这一变量从哈希函数中移出，转而将机器及记录主键都映射到哈希数值空间，解除了机器与数据分布函数之间的直接耦合。大大增强了数据分片的灵活性，但是维护成本很高。

### 范围分片

范围分片首先将所有记录的主键进行排序，然后在排好序的主键空间里将记录划分成数据分片，每个数据分片存储有序的主键空间片段内的所有记录。至于数据分片在物理机的管理方式往往采用LSM树，这是一种高效写入的数据索引结构。

![[Pasted image 20250908175559.jpg]]

很多大规模存储系统都支持上述范围分片模式，比如Yahoo的PNUTS和微软的Azure。Google的BigTable也基本遵循上述模式，不同点在于其数据分片映射表不是单层结构，而是组织成类似B+树的层次结构。

# 第2章——数据分片与路由

大数据领域，增加系统高可用，即将数据进行多副本存储，但是多副本会带来兵法写入的一致性问题。

## 基本原则与设计理念

CAP、BASE、ACID理论

### 原教旨CAP主义

CAP是对“Consistency/Availability/Partition Tolerance”：
- **强一致性**：在分布式系统中的同一数据多副本情形下，对于数据的更新操作体现出的效果与只有单份数据是一样的。
- **可用性**：客户端在任何时刻对大规模数据系统的读／写操作都应该保证在限定延时内完成。
- **分区容忍性**：网络分区通讯有问题，仍然能够继续工作。

1999年Eric Brewer提出该理论，只能实现三个中的两个，一般不舍弃P，故只有AP或CP.

![[Pasted image 20250908180836.jpg]]
- 传统的关系数据库在三要素中选择CA两个因素，即强一致性、高可用性，但是可扩展性与容错性差。
 - NoSQL系统往往更关注AP因素，即高可扩展性和高可用性，但是往往以弱一致性作为代价.


2012年，Eric Brewer又提出P很低概率出现，正常情况下还是要兼顾CAP，在进行差异化、细粒度的CA取舍。修正后的示意图如下，在过程中满足CAP、AP、CAP因素：
![[Pasted image 20250908181729.jpg]]

### ACID原则

- **原子性** （Atomicity）：是指一个事务要么全部执行，要么完全不执行。也就是不允许一个事务只执行了一半就停止。
- **一致性** （Consistency）：事务在开始和结束时，应该始终满足一致性约束条件。
- **事务独立** （Isolation）：如果有多个事务同时执行，彼此之间不需要知晓对方的存在，而且执行时互不影响。
- **持久性** （Durability）：事务的持久性是指事务运行成功以后，对系统状态的更新是永久的，不会无缘由地回滚撤销。

### BASE原则

大多数大数据环境下的云存储系统和NoSQL系统则采纳BASE原则

- **基本可用** （Basically Available）。在绝大多数时间内系统处于可用状态，允许偶尔的失败，所 以称为基本可用。
- **软状态或者柔性状态** （Soft State），是指数据状态不要求在任意时刻都完全保持同步，到目前为止软状态并无一个统一明晰的定义，但是从概念上是可理解的，即处于有状态（State）和无状态（Stateless）之间的中间状态。
- **最终一致性** （Eventual Consistency）。与强一致性相比，最终一致性是一种弱一致性，尽管软状态不要求任意时刻数据保持一致同步，但是最终一致性要求在给定时间窗口内数据会达到一致状态。

### CAP/ACID/BASE三者关系

ACID强调一致性，BASE强调可用性，弱化一致性。CAP和ACID的区别：
- ACID的C是操作一致性约束，CAP的C是数据的强一致性。CAP中的C是ACID中的C所涵盖语义的子集。
- 出现网络分区后，ACID的I只能在某个分区执行
- 当出现网络分区时，多个分区都可以各自进行ACID中的数据持久化（D）操作。

### 幂等性

**分布式的幂等性**：调用方反复执行同一操作与只正确执行一次操作效果相同，即对分布式系统内部状态来说，同一操作调用一次与反复调用多次其状态保持相同。

## 一致性模型分类

理想情况下就只有强一致性
为了在分布式环境下追求高可用和高扩展，采用弱一致性模型，很多NoSQL系统采用弱一致性模型

一致性模型关系图：
![[Pasted image 20250909192340.jpg]]

### 强一致性

更新后所有的读都是更新的值

![[Pasted image 20250909192434.jpg]]
### 最终一致性

无法保证强一致性的时间片段被称为“不一致窗口”，这个窗口可能会看到旧的数值
![[Pasted image 20250909192520.jpg]]

### 因果一致性

有因果依赖的，保证数据的因果一致性，但不一致窗口内仍然会看到旧值
![[Pasted image 20250909192650.jpg]]

### 读你所写一致性

“读你所写”一致性是因果一致性的特例
![[Pasted image 20250909192812.jpg]]

### 会话一致性

读你所写的变体：回话一致性
![[Pasted image 20250909193509.jpg]]

### 单调读一致性

读到一次最新的，后面就都是最新的
![[Pasted image 20250909193611.jpg]]

### 单调写一致性

单调写一致性可以保证其多次写操作的序列化，如果没有这种保证，对于应用开发者来说是很难进行程序开发的。

## 副本更新策略

分布式存储下，数据冗余增加可用性，也增加读操作的并发性。但是一致性问题如何解决呢？

### 同时更新

具体又有两种类型：
- A：不通过任何一致性协议直接同时更新多个副本数据。会有潜在的一致性问题，多个update并发执行
- B：通过某种一致性协议预先处理，有处理成本，所以请求延时会有所增加。

### 主从式更新

所有的更新操作都先提到主副本，主副本再去更新从副本。根据主副本通知从副本的不同机制来区分，存在以下3种类型。
- **同步方式**：主副本等待所有从副本更新完成之后才确认更新操作完成，这可以确保数据的强一致性，但是会存在较大请求延时。
- **异步方式**：主副本在通知从副本更新之前即可确认更新操作。按照读操作又可以分为如下两类：
	- 如果所有读请求都要通过主副本来响应，即任意一个副本接收到读请求后将其转发给主副本；可以保障强一致性，但是会有请求延时。
	- 如果任意一个副本都可以响应读请求，那么请求延时将会大大降低，但是这可能导致读结果不一致的问题。
- **混合方式**：同步和异步混合起来用，按照读操作又可以分为如下两类：
	- 如果读操作的数据至少要从一个同步更新的节点中读出，比如类似于RWN协议的R+W>N，可以保证强一致性，会有请求延时。
	- 如果读操作不要求一定要从至少一个同步更新节点中读出，即RWN协议中的R+W<=N 的模式，会有不一致问题。

### 任意节点更新

数据更新请求可能发给多副本中的任意一个节点，然后由这个节点来负责通知其他副本进行数据更新。有可能有两个不同客户端在同一时刻对同一个数据发出数据更新请求，而此时有可能有两个不同副本各自响应。
- 类型A：同步通知其他副本：存在和“主从式更新”类型A相似的情况，延时更多
- 类型B：异步通知其他副本：存在和“同时更新”策略及“主从式更新”策略的类型B类似的问题。

## 一致性协议

